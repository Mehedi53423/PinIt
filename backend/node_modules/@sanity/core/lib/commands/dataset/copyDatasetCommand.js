"use strict";

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports.default = void 0;

var _eventsource = _interopRequireDefault(require("@sanity/eventsource"));

var _rxjs = require("rxjs");

var _chalk = _interopRequireDefault(require("chalk"));

var _datasetNamePrompt = _interopRequireDefault(require("../../actions/dataset/datasetNamePrompt"));

var _validateDatasetName = _interopRequireDefault(require("../../actions/dataset/validateDatasetName"));

var _debug = _interopRequireDefault(require("../../debug"));

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

const helpText = `
Options
  --detach Start the copy without waiting for it to finish
  --attach <job-id> Attach to the running copy process to show progress
  --skip-history Don't preserve document history on copy

Examples
  sanity dataset copy
  sanity dataset copy <source-dataset>
  sanity dataset copy <source-dataset> <target-dataset>
  sanity dataset copy --skip-history <source-dataset> <target-dataset>
  sanity dataset copy --detach <source-dataset> <target-dataset>
  sanity dataset copy --attach <job-id>
`;

const progress = url => {
  return new _rxjs.Observable(observer => {
    const progressSource = new _eventsource.default(url);

    function onError(error) {
      progressSource.close();
      observer.error(error);
    }

    function onMessage(event) {
      const data = JSON.parse(event.data);

      if (data.state === 'failed') {
        (0, _debug.default)(`Job failed. Data: ${event}`);
        observer.error(event);
      } else if (data.state === 'completed') {
        (0, _debug.default)(`Job succeeded. Data: ${event}`);
        onComplete();
      } else {
        (0, _debug.default)(`Job progressed. Data: ${event}`);
        observer.next(data);
      }
    }

    function onComplete() {
      progressSource.removeEventListener('error', onError);
      progressSource.removeEventListener('channelError', onError);
      progressSource.removeEventListener('job', onMessage);
      progressSource.removeEventListener('done', onComplete);
      progressSource.close();
      observer.complete();
    }

    progressSource.addEventListener('error', onError);
    progressSource.addEventListener('channelError', onError);
    progressSource.addEventListener('job', onMessage);
    progressSource.addEventListener('done', onComplete);
  });
};

const followProgress = (jobId, client, output) => {
  const spinner = output.spinner({
    text: `Copy in progress: 0%`
  }).start();
  const listenUrl = client.getUrl(`jobs/${jobId}/listen`);
  (0, _debug.default)(`Listening to ${listenUrl}`);
  progress(listenUrl).subscribe({
    next: event => {
      const eventProgress = event.progress ? event.progress : 0;
      spinner.text = `Copy in progress: ${eventProgress}%`;
    },
    error: () => {
      spinner.fail('There was an error copying the dataset.');
    },
    complete: () => {
      spinner.succeed(`Copy finished.`);
    }
  });
};

var _default = {
  name: 'copy',
  group: 'dataset',
  signature: '[SOURCE_DATASET] [TARGET_DATASET]',
  helpText,
  description: 'Copies a dataset including its assets to a new dataset',
  action: async (args, context) => {
    const {
      apiClient,
      output,
      prompt
    } = context;
    const flags = args.extOptions;
    const client = apiClient();

    if (flags.attach) {
      const jobId = flags.attach;

      if (!jobId) {
        throw new Error('Please supply a jobId');
      }

      followProgress(jobId, client, output);
      return;
    }

    const [sourceDataset, targetDataset] = args.argsWithoutOptions;
    const shouldSkipHistory = Boolean(flags['skip-history']);
    const nameError = sourceDataset && (0, _validateDatasetName.default)(sourceDataset);

    if (nameError) {
      throw new Error(nameError);
    }

    const existingDatasets = await client.datasets.list().then(datasets => datasets.map(ds => ds.name));
    const sourceDatasetName = await (sourceDataset || (0, _datasetNamePrompt.default)(prompt, {
      message: 'Source dataset name:'
    }));

    if (!existingDatasets.includes(sourceDatasetName)) {
      throw new Error(`Source dataset "${sourceDatasetName}" doesn't exist`);
    }

    const targetDatasetName = await (targetDataset || (0, _datasetNamePrompt.default)(prompt, {
      message: 'Target dataset name:'
    }));

    if (existingDatasets.includes(targetDatasetName)) {
      throw new Error(`Target dataset "${targetDatasetName}" already exists`);
    }

    const err = (0, _validateDatasetName.default)(targetDatasetName);

    if (err) {
      throw new Error(err);
    }

    try {
      const response = await client.request({
        method: 'PUT',
        uri: `/datasets/${sourceDatasetName}/copy`,
        body: {
          targetDataset: targetDatasetName,
          skipHistory: shouldSkipHistory
        }
      });
      output.print(`Copying dataset ${_chalk.default.green(sourceDatasetName)} to ${_chalk.default.green(targetDatasetName)}...`);

      if (flags.detach) {
        output.print(`Copy initiated.`);
        output.print(`\nRun:\n\n    sanity dataset copy --attach ${response.jobId}\n\nto watch attach`);
        return;
      }

      followProgress(response.jobId, client, output);
    } catch (error) {
      if (error.statusCode) {
        output.print(`${_chalk.default.red(`Dataset copying failed:\n${error.response.body.message}`)}\n`);
      } else {
        output.print(`${_chalk.default.red(`Dataset copying failed:\n${error.message}`)}\n`);
      }
    }
  }
};
exports.default = _default;